{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.2"
    },
    "colab": {
      "name": "Day098_Python_generator.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHasvpvoOQuL",
        "colab_type": "text"
      },
      "source": [
        "## 作業"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iS0DIKSzpUpc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "aa23d303-f924-406b-9fe1-cdbbc0e23c22"
      },
      "source": [
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.optimizers import RMSprop, Adam\n",
        "import os"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMSuIJfApanU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "8bebc1b3-d305-44d8-8feb-f7193d259985"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 4s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-KSidldpfal",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 128 # batch 的大小，如果出現 OOM error，請降低這個值\n",
        "num_classes = 10 # 類別的數量，Cifar 10 共有 10 個類別\n",
        "epochs = 10 # 訓練的 epochs 數量\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jeKJ4Y-ppb5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "59fef18d-7e87-40e6-e10d-575715c09173"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "# Convert class vectors to binary class matrices.\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUT-7TTcsYgY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cifar_generator(image_array, batch_size=32):\n",
        "    while True:\n",
        "        for indexs in range(0, len(image_array), batch_size):\n",
        "            images = x_train[indexs: indexs+batch_size]\n",
        "            labels = y_train[indexs: indexs+batch_size]\n",
        "            yield images, labels\n",
        "            \n",
        "            \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "494FZJAb9pkK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import ReduceLROnPlateau\n",
        "learning_rate_function = ReduceLROnPlateau(monitor='val_acc', \n",
        "                                            patience=3, \n",
        "                                            verbose=1, \n",
        "                                            factor=0.5, \n",
        "                                            min_lr=0.00001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_IXeNdrp_cX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "outputId": "bac59d7b-8454-48c8-c3fd-0b3f659dec2c"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(16, (5, 5), padding='same',\n",
        "                 input_shape=x_train.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(32, (5, 5)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "\n",
        "model.add(Conv2D(128, (5, 5)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "model.summary()\n",
        "\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_20 (Conv2D)           (None, 32, 32, 16)        1216      \n",
            "_________________________________________________________________\n",
            "activation_32 (Activation)   (None, 32, 32, 16)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_14 (MaxPooling (None, 16, 16, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_21 (Conv2D)           (None, 12, 12, 32)        12832     \n",
            "_________________________________________________________________\n",
            "activation_33 (Activation)   (None, 12, 12, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_15 (MaxPooling (None, 6, 6, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_22 (Conv2D)           (None, 2, 2, 128)         102528    \n",
            "_________________________________________________________________\n",
            "activation_34 (Activation)   (None, 2, 2, 128)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_16 (MaxPooling (None, 1, 1, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_7 (Flatten)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "activation_35 (Activation)   (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 10)                1290      \n",
            "_________________________________________________________________\n",
            "activation_36 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 134,378\n",
            "Trainable params: 134,378\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASwe7h3k6MZf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b7f2e1bf-3117-480d-b2a0-51cf14f4ab61"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=RMSprop(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "\n",
        "history = model.fit_generator(cifar_generator(x_train),\n",
        "                              epochs=50,\n",
        "                              steps_per_epoch=len(x_train)/32,\n",
        "                              verbose=1,\n",
        "                              validation_data=(x_test, y_test),\n",
        "                              callbacks = [learning_rate_function])\n",
        "\n",
        "'''\n",
        "  train_history = model.fit_generator(train_generator, \n",
        "                                    steps_per_epoch=300, \n",
        "                                    epochs=30, \n",
        "                                    verbose=1,\n",
        "                                    validation_data=(x_val, y_val_onehot),\n",
        "                                    callbacks=[learning_rate_function])\n",
        "'''\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "1563/1562 [==============================] - 10s 6ms/step - loss: 1.6472 - acc: 0.4034 - val_loss: 1.6553 - val_acc: 0.4448\n",
            "Epoch 2/50\n",
            "1563/1562 [==============================] - 9s 6ms/step - loss: 1.2732 - acc: 0.5551 - val_loss: 1.2956 - val_acc: 0.5466\n",
            "Epoch 3/50\n",
            "1563/1562 [==============================] - 9s 6ms/step - loss: 1.1274 - acc: 0.6131 - val_loss: 1.2334 - val_acc: 0.5874\n",
            "Epoch 4/50\n",
            "1563/1562 [==============================] - 9s 6ms/step - loss: 1.0522 - acc: 0.6433 - val_loss: 1.3258 - val_acc: 0.5699\n",
            "Epoch 5/50\n",
            "1563/1562 [==============================] - 9s 6ms/step - loss: 1.0232 - acc: 0.6614 - val_loss: 1.2468 - val_acc: 0.6317\n",
            "Epoch 6/50\n",
            "1563/1562 [==============================] - 9s 6ms/step - loss: 1.0343 - acc: 0.6597 - val_loss: 1.1659 - val_acc: 0.6211\n",
            "Epoch 7/50\n",
            "1563/1562 [==============================] - 9s 6ms/step - loss: 1.0694 - acc: 0.6516 - val_loss: 1.3027 - val_acc: 0.6191\n",
            "Epoch 8/50\n",
            "1563/1562 [==============================] - 9s 6ms/step - loss: 1.1029 - acc: 0.6424 - val_loss: 1.3659 - val_acc: 0.5514\n",
            "\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "Epoch 9/50\n",
            "1563/1562 [==============================] - 9s 6ms/step - loss: 0.9439 - acc: 0.6946 - val_loss: 1.1742 - val_acc: 0.6552\n",
            "Epoch 10/50\n",
            "1563/1562 [==============================] - 9s 6ms/step - loss: 0.9453 - acc: 0.6952 - val_loss: 1.2614 - val_acc: 0.6482\n",
            "Epoch 11/50\n",
            "1563/1562 [==============================] - 9s 6ms/step - loss: 0.9604 - acc: 0.6900 - val_loss: 1.2665 - val_acc: 0.6163\n",
            "Epoch 12/50\n",
            "1563/1562 [==============================] - 9s 6ms/step - loss: 0.9811 - acc: 0.6878 - val_loss: 1.2633 - val_acc: 0.6083\n",
            "\n",
            "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "Epoch 13/50\n",
            "1563/1562 [==============================] - 9s 6ms/step - loss: 0.8526 - acc: 0.7265 - val_loss: 1.0637 - val_acc: 0.6661\n",
            "Epoch 14/50\n",
            "1563/1562 [==============================] - 9s 6ms/step - loss: 0.8420 - acc: 0.7284 - val_loss: 1.1724 - val_acc: 0.6753\n",
            "Epoch 15/50\n",
            "1563/1562 [==============================] - 9s 6ms/step - loss: 0.8469 - acc: 0.7265 - val_loss: 1.0906 - val_acc: 0.6573\n",
            "Epoch 16/50\n",
            "1563/1562 [==============================] - 9s 6ms/step - loss: 0.8450 - acc: 0.7285 - val_loss: 1.0941 - val_acc: 0.6482\n",
            "Epoch 17/50\n",
            "1563/1562 [==============================] - 9s 6ms/step - loss: 0.8491 - acc: 0.7271 - val_loss: 1.1500 - val_acc: 0.6705\n",
            "\n",
            "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "Epoch 18/50\n",
            "1563/1562 [==============================] - 9s 6ms/step - loss: 0.7691 - acc: 0.7522 - val_loss: 1.0945 - val_acc: 0.6705\n",
            "Epoch 19/50\n",
            "1563/1562 [==============================] - 9s 6ms/step - loss: 0.7672 - acc: 0.7532 - val_loss: 1.0922 - val_acc: 0.6622\n",
            "Epoch 20/50\n",
            "1563/1562 [==============================] - 9s 6ms/step - loss: 0.7596 - acc: 0.7540 - val_loss: 1.1124 - val_acc: 0.6715\n",
            "\n",
            "Epoch 00020: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "Epoch 21/50\n",
            "1563/1562 [==============================] - 9s 6ms/step - loss: 0.7274 - acc: 0.7649 - val_loss: 1.1626 - val_acc: 0.6845\n",
            "Epoch 22/50\n",
            "1563/1562 [==============================] - 9s 6ms/step - loss: 0.7211 - acc: 0.7666 - val_loss: 1.1497 - val_acc: 0.6751\n",
            "Epoch 23/50\n",
            "1563/1562 [==============================] - 9s 6ms/step - loss: 0.7220 - acc: 0.7670 - val_loss: 1.1651 - val_acc: 0.6790\n",
            "Epoch 24/50\n",
            "1563/1562 [==============================] - 9s 6ms/step - loss: 0.7161 - acc: 0.7678 - val_loss: 1.1295 - val_acc: 0.6777\n",
            "\n",
            "Epoch 00024: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "Epoch 25/50\n",
            "1563/1562 [==============================] - 9s 6ms/step - loss: 0.7019 - acc: 0.7740 - val_loss: 1.1359 - val_acc: 0.6849\n",
            "Epoch 26/50\n",
            "1563/1562 [==============================] - 9s 6ms/step - loss: 0.6970 - acc: 0.7749 - val_loss: 1.1449 - val_acc: 0.6809\n",
            "Epoch 27/50\n",
            "1563/1562 [==============================] - 9s 6ms/step - loss: 0.6917 - acc: 0.7770 - val_loss: 1.1550 - val_acc: 0.6826\n",
            "Epoch 28/50\n",
            "1563/1562 [==============================] - 10s 6ms/step - loss: 0.6982 - acc: 0.7772 - val_loss: 1.1560 - val_acc: 0.6859\n",
            "Epoch 29/50\n",
            "1563/1562 [==============================] - 9s 6ms/step - loss: 0.6886 - acc: 0.7766 - val_loss: 1.1395 - val_acc: 0.6829\n",
            "Epoch 30/50\n",
            "1563/1562 [==============================] - 9s 6ms/step - loss: 0.6892 - acc: 0.7759 - val_loss: 1.1600 - val_acc: 0.6851\n",
            "Epoch 31/50\n",
            "1563/1562 [==============================] - 9s 6ms/step - loss: 0.6927 - acc: 0.7759 - val_loss: 1.1540 - val_acc: 0.6824\n",
            "\n",
            "Epoch 00031: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
            "Epoch 32/50\n",
            "1563/1562 [==============================] - 9s 6ms/step - loss: 0.6844 - acc: 0.7796 - val_loss: 1.1643 - val_acc: 0.6843\n",
            "Epoch 33/50\n",
            "1563/1562 [==============================] - 9s 6ms/step - loss: 0.6814 - acc: 0.7801 - val_loss: 1.1703 - val_acc: 0.6880\n",
            "Epoch 34/50\n",
            "1563/1562 [==============================] - 9s 6ms/step - loss: 0.6812 - acc: 0.7801 - val_loss: 1.1764 - val_acc: 0.6865\n",
            "Epoch 35/50\n",
            "1563/1562 [==============================] - 9s 6ms/step - loss: 0.6762 - acc: 0.7807 - val_loss: 1.1681 - val_acc: 0.6876\n",
            "Epoch 36/50\n",
            "1563/1562 [==============================] - 9s 6ms/step - loss: 0.6792 - acc: 0.7817 - val_loss: 1.1517 - val_acc: 0.6840\n",
            "\n",
            "Epoch 00036: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
            "Epoch 37/50\n",
            "1563/1562 [==============================] - 9s 6ms/step - loss: 0.6754 - acc: 0.7810 - val_loss: 1.1876 - val_acc: 0.6874\n",
            "Epoch 38/50\n",
            "1563/1562 [==============================] - 9s 6ms/step - loss: 0.6751 - acc: 0.7809 - val_loss: 1.1657 - val_acc: 0.6855\n",
            "Epoch 39/50\n",
            "1563/1562 [==============================] - 9s 6ms/step - loss: 0.6702 - acc: 0.7841 - val_loss: 1.1784 - val_acc: 0.6853\n",
            "Epoch 40/50\n",
            "1563/1562 [==============================] - 9s 6ms/step - loss: 0.6717 - acc: 0.7824 - val_loss: 1.1717 - val_acc: 0.6851\n",
            "Epoch 41/50\n",
            "1563/1562 [==============================] - 9s 6ms/step - loss: 0.6716 - acc: 0.7816 - val_loss: 1.1734 - val_acc: 0.6863\n",
            "Epoch 42/50\n",
            "1563/1562 [==============================] - 9s 6ms/step - loss: 0.6688 - acc: 0.7819 - val_loss: 1.1794 - val_acc: 0.6881\n",
            "Epoch 43/50\n",
            "1563/1562 [==============================] - 9s 6ms/step - loss: 0.6706 - acc: 0.7826 - val_loss: 1.1951 - val_acc: 0.6867\n",
            "Epoch 44/50\n",
            "1563/1562 [==============================] - 9s 6ms/step - loss: 0.6768 - acc: 0.7821 - val_loss: 1.1766 - val_acc: 0.6878\n",
            "Epoch 45/50\n",
            "1563/1562 [==============================] - 9s 6ms/step - loss: 0.6696 - acc: 0.7862 - val_loss: 1.1829 - val_acc: 0.6876\n",
            "Epoch 46/50\n",
            "1563/1562 [==============================] - 9s 6ms/step - loss: 0.6698 - acc: 0.7867 - val_loss: 1.1790 - val_acc: 0.6866\n",
            "Epoch 47/50\n",
            "1563/1562 [==============================] - 9s 6ms/step - loss: 0.6700 - acc: 0.7847 - val_loss: 1.1846 - val_acc: 0.6861\n",
            "Epoch 48/50\n",
            "1563/1562 [==============================] - 9s 6ms/step - loss: 0.6677 - acc: 0.7836 - val_loss: 1.1868 - val_acc: 0.6863\n",
            "Epoch 49/50\n",
            "1563/1562 [==============================] - 9s 6ms/step - loss: 0.6739 - acc: 0.7834 - val_loss: 1.1899 - val_acc: 0.6846\n",
            "Epoch 50/50\n",
            "1563/1562 [==============================] - 9s 6ms/step - loss: 0.6654 - acc: 0.7837 - val_loss: 1.1887 - val_acc: 0.6881\n",
            "Test loss: 1.1887300065994262\n",
            "Test accuracy: 0.6881\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}