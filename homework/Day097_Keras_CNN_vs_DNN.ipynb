{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.2"
    },
    "colab": {
      "name": "Day097_Keras_CNN_vs_DNN.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JsZ0IEuIZoN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d249cb08-ea5e-47de-99bb-bb722cfd47f5"
      },
      "source": [
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.optimizers import RMSprop, Adam\n",
        "import os"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQkppyCJI8c-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "265d981f-436e-41f0-9503-3f93f6ed7ffb"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 12s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2TuSPHpIZoY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "01fa50c1-6a30-4146-9d9a-a4ae88862f63"
      },
      "source": [
        "batch_size = 128 # batch 的大小，如果出現 OOM error，請降低這個值\n",
        "num_classes = 10 # 類別的數量，Cifar 10 共有 10 個類別\n",
        "epochs = 10 # 訓練的 epochs 數量\n",
        "\n",
        "# 讀取資料並檢視\n",
        "\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# 對 label 進行 one-hot encoding (y_trian 原本是純數字)\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "alf7ICM8IZod",
        "colab_type": "text"
      },
      "source": [
        "## 首先我們使用一般的 DNN (MLP) 來訓練\n",
        "由於 DNN 只能輸入一維的資料，我們要先將影像進行攤平，若 (50000, 32, 32, 3) 的影像，攤平後會變成 (50000, 32*32*3) = (50000, 3072)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvS5o7U6IZoe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "14d5a3ee-e29a-41ae-9bde-aabc109a6da7"
      },
      "source": [
        "# 將資料攤平成一維資料\n",
        "x_train = x_train.reshape(50000, 3072) \n",
        "x_test = x_test.reshape(10000, 3072)\n",
        "\n",
        "# 將資料變為 float32 並標準化\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YVqcEVNIZoj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "01c41877-1fb8-4f04-81b0-d4a81be7dad7"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(512, activation='relu', input_shape=(3072,)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=RMSprop(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_test, y_test))\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0820 08:30:05.906101 139843476461440 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0820 08:30:05.948050 139843476461440 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0820 08:30:05.957260 139843476461440 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0820 08:30:05.977272 139843476461440 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "W0820 08:30:05.988865 139843476461440 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W0820 08:30:06.074943 139843476461440 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0820 08:30:06.088336 139843476461440 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "W0820 08:30:06.235329 139843476461440 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 512)               1573376   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 1,841,162\n",
            "Trainable params: 1,841,162\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "50000/50000 [==============================] - 7s 144us/step - loss: 2.1892 - acc: 0.2461 - val_loss: 1.8703 - val_acc: 0.3321\n",
            "Epoch 2/10\n",
            "50000/50000 [==============================] - 4s 71us/step - loss: 1.8601 - acc: 0.3284 - val_loss: 1.7361 - val_acc: 0.3930\n",
            "Epoch 3/10\n",
            "50000/50000 [==============================] - 3s 69us/step - loss: 1.7835 - acc: 0.3557 - val_loss: 1.7023 - val_acc: 0.3878\n",
            "Epoch 4/10\n",
            "50000/50000 [==============================] - 3s 70us/step - loss: 1.7389 - acc: 0.3726 - val_loss: 1.7779 - val_acc: 0.3624\n",
            "Epoch 5/10\n",
            "50000/50000 [==============================] - 4s 70us/step - loss: 1.7003 - acc: 0.3898 - val_loss: 1.6357 - val_acc: 0.4268\n",
            "Epoch 6/10\n",
            "50000/50000 [==============================] - 3s 70us/step - loss: 1.6765 - acc: 0.3975 - val_loss: 1.5848 - val_acc: 0.4361\n",
            "Epoch 7/10\n",
            "50000/50000 [==============================] - 3s 70us/step - loss: 1.6567 - acc: 0.4044 - val_loss: 1.5898 - val_acc: 0.4256\n",
            "Epoch 8/10\n",
            "50000/50000 [==============================] - 3s 69us/step - loss: 1.6407 - acc: 0.4147 - val_loss: 1.6001 - val_acc: 0.4313\n",
            "Epoch 9/10\n",
            "50000/50000 [==============================] - 3s 69us/step - loss: 1.6217 - acc: 0.4202 - val_loss: 1.5612 - val_acc: 0.4484\n",
            "Epoch 10/10\n",
            "50000/50000 [==============================] - 3s 69us/step - loss: 1.6118 - acc: 0.4232 - val_loss: 1.6128 - val_acc: 0.4163\n",
            "Test loss: 1.6128101125717162\n",
            "Test accuracy: 0.4163\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mtlTCK6IZom",
        "colab_type": "text"
      },
      "source": [
        "## 接下來我們使用 CNN 來訓練神經網路\n",
        "CNN 的原理非常適合處理影像類的資料，就讓我們來看看，同樣的訓練條件，CNN 是否顯著優於 DNN 呢?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epVR7opaIZon",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "25625abf-ccee-41f0-d478-9104910d09b5"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "# Convert class vectors to binary class matrices.\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d84KqPbfIZor",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b61dd60b-791d-4b01-c8f3-655ab3b73d79"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), padding='same',\n",
        "                 input_shape=x_train.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=RMSprop(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_test, y_test))\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0820 08:32:32.105344 139843476461440 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 30, 30, 32)        9248      \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 30, 30, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 15, 15, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 15, 15, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 13, 13, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 13, 13, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 512)               1180160   \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                5130      \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 1,250,858\n",
            "Trainable params: 1,250,858\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "50000/50000 [==============================] - 14s 284us/step - loss: 1.7218 - acc: 0.3764 - val_loss: 1.3323 - val_acc: 0.5243\n",
            "Epoch 2/10\n",
            "50000/50000 [==============================] - 11s 227us/step - loss: 1.2833 - acc: 0.5448 - val_loss: 1.1700 - val_acc: 0.5889\n",
            "Epoch 3/10\n",
            "50000/50000 [==============================] - 11s 227us/step - loss: 1.0743 - acc: 0.6244 - val_loss: 1.0304 - val_acc: 0.6377\n",
            "Epoch 4/10\n",
            "50000/50000 [==============================] - 11s 227us/step - loss: 0.9516 - acc: 0.6672 - val_loss: 0.8893 - val_acc: 0.6865\n",
            "Epoch 5/10\n",
            "50000/50000 [==============================] - 11s 228us/step - loss: 0.8651 - acc: 0.6993 - val_loss: 0.8121 - val_acc: 0.7150\n",
            "Epoch 6/10\n",
            "50000/50000 [==============================] - 11s 230us/step - loss: 0.8030 - acc: 0.7206 - val_loss: 0.7869 - val_acc: 0.7265\n",
            "Epoch 7/10\n",
            "50000/50000 [==============================] - 11s 230us/step - loss: 0.7569 - acc: 0.7370 - val_loss: 0.8174 - val_acc: 0.7193\n",
            "Epoch 8/10\n",
            "50000/50000 [==============================] - 11s 228us/step - loss: 0.7133 - acc: 0.7534 - val_loss: 0.7211 - val_acc: 0.7556\n",
            "Epoch 9/10\n",
            "50000/50000 [==============================] - 11s 228us/step - loss: 0.6850 - acc: 0.7619 - val_loss: 0.6997 - val_acc: 0.7669\n",
            "Epoch 10/10\n",
            "50000/50000 [==============================] - 11s 228us/step - loss: 0.6612 - acc: 0.7733 - val_loss: 0.7322 - val_acc: 0.7576\n",
            "Test loss: 0.7322441259384155\n",
            "Test accuracy: 0.7576\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CluAWR67K0MB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##更改batch size \n",
        "batch_size = 32 # batch 的大小，如果出現 OOM error，請降低這個值"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAy7niHdLDzw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "3415574f-65bb-446c-fd48-1540b461f679"
      },
      "source": [
        "## 重跑一次\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=RMSprop(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_test, y_test))\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "50000/50000 [==============================] - 24s 485us/step - loss: 0.8532 - acc: 0.7172 - val_loss: 0.8946 - val_acc: 0.7084\n",
            "Epoch 2/10\n",
            "50000/50000 [==============================] - 23s 462us/step - loss: 0.9383 - acc: 0.6936 - val_loss: 0.9212 - val_acc: 0.6972\n",
            "Epoch 3/10\n",
            "50000/50000 [==============================] - 23s 462us/step - loss: 0.9901 - acc: 0.6815 - val_loss: 0.9965 - val_acc: 0.6685\n",
            "Epoch 4/10\n",
            "50000/50000 [==============================] - 23s 467us/step - loss: 1.0250 - acc: 0.6713 - val_loss: 1.1615 - val_acc: 0.6486\n",
            "Epoch 5/10\n",
            "50000/50000 [==============================] - 23s 463us/step - loss: 1.0756 - acc: 0.6554 - val_loss: 1.2413 - val_acc: 0.6238\n",
            "Epoch 6/10\n",
            "50000/50000 [==============================] - 22s 444us/step - loss: 1.1173 - acc: 0.6438 - val_loss: 1.1723 - val_acc: 0.6439\n",
            "Epoch 7/10\n",
            "50000/50000 [==============================] - 22s 440us/step - loss: 1.1796 - acc: 0.6274 - val_loss: 1.1458 - val_acc: 0.6315\n",
            "Epoch 8/10\n",
            "50000/50000 [==============================] - 22s 440us/step - loss: 1.2179 - acc: 0.6152 - val_loss: 0.9402 - val_acc: 0.6848\n",
            "Epoch 9/10\n",
            "50000/50000 [==============================] - 22s 439us/step - loss: 1.2495 - acc: 0.6057 - val_loss: 1.2270 - val_acc: 0.6059\n",
            "Epoch 10/10\n",
            "50000/50000 [==============================] - 22s 440us/step - loss: 1.2874 - acc: 0.5928 - val_loss: 1.6469 - val_acc: 0.6334\n",
            "Test loss: 1.6468728567123414\n",
            "Test accuracy: 0.6334\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYeryPkAMeWm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a2f5f4b6-acc0-4415-b699-23746ecaf115"
      },
      "source": [
        "## 更改卷積大小皆為6*6\n",
        "batch_size = 128\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (6, 6), padding='same',\n",
        "                 input_shape=x_train.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(32, (6, 6)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (6, 6), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (6, 6)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=RMSprop(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_test, y_test))\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_5 (Conv2D)            (None, 32, 32, 32)        3488      \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 27, 27, 32)        36896     \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 27, 27, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 13, 13, 64)        73792     \n",
            "_________________________________________________________________\n",
            "activation_9 (Activation)    (None, 13, 13, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 8, 8, 64)          147520    \n",
            "_________________________________________________________________\n",
            "activation_10 (Activation)   (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 4, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 4, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "activation_11 (Activation)   (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 10)                5130      \n",
            "_________________________________________________________________\n",
            "activation_12 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 791,626\n",
            "Trainable params: 791,626\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "50000/50000 [==============================] - 14s 274us/step - loss: 1.9774 - acc: 0.2757 - val_loss: 1.5256 - val_acc: 0.4374\n",
            "Epoch 2/10\n",
            "50000/50000 [==============================] - 13s 257us/step - loss: 1.5207 - acc: 0.4594 - val_loss: 1.5127 - val_acc: 0.4816\n",
            "Epoch 3/10\n",
            "50000/50000 [==============================] - 13s 256us/step - loss: 1.3007 - acc: 0.5394 - val_loss: 1.5148 - val_acc: 0.4957\n",
            "Epoch 4/10\n",
            "50000/50000 [==============================] - 13s 257us/step - loss: 1.1498 - acc: 0.5989 - val_loss: 1.1143 - val_acc: 0.6135\n",
            "Epoch 5/10\n",
            "50000/50000 [==============================] - 13s 257us/step - loss: 1.0436 - acc: 0.6371 - val_loss: 0.9793 - val_acc: 0.6588\n",
            "Epoch 6/10\n",
            "50000/50000 [==============================] - 13s 258us/step - loss: 0.9665 - acc: 0.6641 - val_loss: 0.9413 - val_acc: 0.6851\n",
            "Epoch 7/10\n",
            "50000/50000 [==============================] - 13s 256us/step - loss: 0.9092 - acc: 0.6875 - val_loss: 0.8840 - val_acc: 0.7011\n",
            "Epoch 8/10\n",
            "50000/50000 [==============================] - 13s 256us/step - loss: 0.8629 - acc: 0.7037 - val_loss: 0.8924 - val_acc: 0.6958\n",
            "Epoch 9/10\n",
            "50000/50000 [==============================] - 13s 255us/step - loss: 0.8359 - acc: 0.7125 - val_loss: 0.9147 - val_acc: 0.7122\n",
            "Epoch 10/10\n",
            "50000/50000 [==============================] - 13s 256us/step - loss: 0.8094 - acc: 0.7235 - val_loss: 0.9295 - val_acc: 0.6956\n",
            "Test loss: 0.929543705368042\n",
            "Test accuracy: 0.6956\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A88DuTtJNu4y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1529df07-ef31-4bc7-eb25-0850209d146b"
      },
      "source": [
        "## 提高epoch 50\n",
        "batch_size = 128 # batch 的大小，如果出現 OOM error，請降低這個值\n",
        "num_classes = 10 # 類別的數量，Cifar 10 共有 10 個類別\n",
        "epochs = 50 # 訓練的 epochs 數量\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), padding='same',\n",
        "                 input_shape=x_train.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=RMSprop(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_test, y_test))\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_9 (Conv2D)            (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "activation_13 (Activation)   (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 30, 30, 32)        9248      \n",
            "_________________________________________________________________\n",
            "activation_14 (Activation)   (None, 30, 30, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 15, 15, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_15 (Activation)   (None, 15, 15, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 13, 13, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_16 (Activation)   (None, 13, 13, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 512)               1180160   \n",
            "_________________________________________________________________\n",
            "activation_17 (Activation)   (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 10)                5130      \n",
            "_________________________________________________________________\n",
            "activation_18 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 1,250,858\n",
            "Trainable params: 1,250,858\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "50000/50000 [==============================] - 13s 266us/step - loss: 1.7818 - acc: 0.3550 - val_loss: 1.3372 - val_acc: 0.5193\n",
            "Epoch 2/50\n",
            "50000/50000 [==============================] - 12s 239us/step - loss: 1.3395 - acc: 0.5240 - val_loss: 1.2707 - val_acc: 0.5599\n",
            "Epoch 3/50\n",
            "50000/50000 [==============================] - 12s 241us/step - loss: 1.1288 - acc: 0.6029 - val_loss: 1.0789 - val_acc: 0.6254\n",
            "Epoch 4/50\n",
            "50000/50000 [==============================] - 12s 240us/step - loss: 0.9933 - acc: 0.6516 - val_loss: 0.9112 - val_acc: 0.6789\n",
            "Epoch 5/50\n",
            "50000/50000 [==============================] - 12s 240us/step - loss: 0.8975 - acc: 0.6871 - val_loss: 0.8552 - val_acc: 0.7058\n",
            "Epoch 6/50\n",
            "50000/50000 [==============================] - 12s 240us/step - loss: 0.8254 - acc: 0.7119 - val_loss: 0.8504 - val_acc: 0.7148\n",
            "Epoch 7/50\n",
            "50000/50000 [==============================] - 12s 234us/step - loss: 0.7750 - acc: 0.7315 - val_loss: 0.7596 - val_acc: 0.7396\n",
            "Epoch 8/50\n",
            "50000/50000 [==============================] - 12s 231us/step - loss: 0.7320 - acc: 0.7470 - val_loss: 0.7577 - val_acc: 0.7435\n",
            "Epoch 9/50\n",
            "50000/50000 [==============================] - 12s 231us/step - loss: 0.7011 - acc: 0.7591 - val_loss: 0.7959 - val_acc: 0.7491\n",
            "Epoch 10/50\n",
            "50000/50000 [==============================] - 12s 232us/step - loss: 0.6759 - acc: 0.7679 - val_loss: 0.7237 - val_acc: 0.7663\n",
            "Epoch 11/50\n",
            "50000/50000 [==============================] - 12s 232us/step - loss: 0.6597 - acc: 0.7741 - val_loss: 0.6749 - val_acc: 0.7773\n",
            "Epoch 12/50\n",
            "50000/50000 [==============================] - 12s 231us/step - loss: 0.6478 - acc: 0.7807 - val_loss: 0.6929 - val_acc: 0.7713\n",
            "Epoch 13/50\n",
            "50000/50000 [==============================] - 12s 231us/step - loss: 0.6332 - acc: 0.7849 - val_loss: 0.7934 - val_acc: 0.7561\n",
            "Epoch 14/50\n",
            "50000/50000 [==============================] - 12s 231us/step - loss: 0.6341 - acc: 0.7854 - val_loss: 0.7277 - val_acc: 0.7771\n",
            "Epoch 15/50\n",
            "50000/50000 [==============================] - 12s 231us/step - loss: 0.6281 - acc: 0.7887 - val_loss: 0.7465 - val_acc: 0.7740\n",
            "Epoch 16/50\n",
            "50000/50000 [==============================] - 12s 231us/step - loss: 0.6262 - acc: 0.7910 - val_loss: 0.6342 - val_acc: 0.7840\n",
            "Epoch 17/50\n",
            "50000/50000 [==============================] - 11s 228us/step - loss: 0.6172 - acc: 0.7935 - val_loss: 0.6746 - val_acc: 0.7790\n",
            "Epoch 18/50\n",
            "50000/50000 [==============================] - 11s 228us/step - loss: 0.6214 - acc: 0.7937 - val_loss: 0.7852 - val_acc: 0.7595\n",
            "Epoch 19/50\n",
            "50000/50000 [==============================] - 11s 230us/step - loss: 0.6151 - acc: 0.7966 - val_loss: 0.8160 - val_acc: 0.7728\n",
            "Epoch 20/50\n",
            "50000/50000 [==============================] - 12s 230us/step - loss: 0.6116 - acc: 0.7979 - val_loss: 0.7240 - val_acc: 0.7797\n",
            "Epoch 21/50\n",
            "50000/50000 [==============================] - 11s 228us/step - loss: 0.6078 - acc: 0.8005 - val_loss: 0.7328 - val_acc: 0.7865\n",
            "Epoch 22/50\n",
            "50000/50000 [==============================] - 11s 228us/step - loss: 0.5997 - acc: 0.8027 - val_loss: 0.6587 - val_acc: 0.7845\n",
            "Epoch 23/50\n",
            "50000/50000 [==============================] - 11s 228us/step - loss: 0.6024 - acc: 0.8039 - val_loss: 0.7194 - val_acc: 0.7879\n",
            "Epoch 24/50\n",
            "50000/50000 [==============================] - 11s 227us/step - loss: 0.6039 - acc: 0.8017 - val_loss: 0.7048 - val_acc: 0.7833\n",
            "Epoch 25/50\n",
            "50000/50000 [==============================] - 11s 227us/step - loss: 0.6030 - acc: 0.8043 - val_loss: 0.6985 - val_acc: 0.7821\n",
            "Epoch 26/50\n",
            "50000/50000 [==============================] - 11s 227us/step - loss: 0.5966 - acc: 0.8060 - val_loss: 0.6857 - val_acc: 0.7765\n",
            "Epoch 27/50\n",
            "50000/50000 [==============================] - 11s 227us/step - loss: 0.6055 - acc: 0.8011 - val_loss: 0.7524 - val_acc: 0.7926\n",
            "Epoch 28/50\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 0.6093 - acc: 0.8044 - val_loss: 0.7886 - val_acc: 0.7469\n",
            "Epoch 29/50\n",
            "50000/50000 [==============================] - 11s 227us/step - loss: 0.6027 - acc: 0.8028 - val_loss: 0.7412 - val_acc: 0.7641\n",
            "Epoch 30/50\n",
            "50000/50000 [==============================] - 12s 232us/step - loss: 0.6092 - acc: 0.8023 - val_loss: 0.7063 - val_acc: 0.7831\n",
            "Epoch 31/50\n",
            "50000/50000 [==============================] - 11s 228us/step - loss: 0.6030 - acc: 0.8033 - val_loss: 0.7296 - val_acc: 0.7757\n",
            "Epoch 32/50\n",
            "50000/50000 [==============================] - 11s 228us/step - loss: 0.6168 - acc: 0.8018 - val_loss: 0.7373 - val_acc: 0.7637\n",
            "Epoch 33/50\n",
            "50000/50000 [==============================] - 11s 229us/step - loss: 0.6201 - acc: 0.8013 - val_loss: 0.7229 - val_acc: 0.7747\n",
            "Epoch 34/50\n",
            "50000/50000 [==============================] - 11s 229us/step - loss: 0.6162 - acc: 0.7988 - val_loss: 0.7150 - val_acc: 0.7744\n",
            "Epoch 35/50\n",
            "50000/50000 [==============================] - 11s 230us/step - loss: 0.6258 - acc: 0.7997 - val_loss: 0.8493 - val_acc: 0.7627\n",
            "Epoch 36/50\n",
            "50000/50000 [==============================] - 11s 230us/step - loss: 0.6198 - acc: 0.8026 - val_loss: 0.7136 - val_acc: 0.7664\n",
            "Epoch 37/50\n",
            "50000/50000 [==============================] - 11s 230us/step - loss: 0.6249 - acc: 0.7987 - val_loss: 0.7198 - val_acc: 0.7776\n",
            "Epoch 38/50\n",
            "50000/50000 [==============================] - 12s 230us/step - loss: 0.6264 - acc: 0.7989 - val_loss: 0.9089 - val_acc: 0.7662\n",
            "Epoch 39/50\n",
            "50000/50000 [==============================] - 12s 230us/step - loss: 0.6279 - acc: 0.7966 - val_loss: 0.6949 - val_acc: 0.7825\n",
            "Epoch 40/50\n",
            "50000/50000 [==============================] - 11s 229us/step - loss: 0.6272 - acc: 0.7986 - val_loss: 0.6987 - val_acc: 0.7782\n",
            "Epoch 41/50\n",
            "50000/50000 [==============================] - 11s 229us/step - loss: 0.6376 - acc: 0.7941 - val_loss: 0.7885 - val_acc: 0.7881\n",
            "Epoch 42/50\n",
            "50000/50000 [==============================] - 11s 229us/step - loss: 0.6356 - acc: 0.7973 - val_loss: 0.7592 - val_acc: 0.7809\n",
            "Epoch 43/50\n",
            "50000/50000 [==============================] - 11s 230us/step - loss: 0.6445 - acc: 0.7937 - val_loss: 0.7116 - val_acc: 0.7696\n",
            "Epoch 44/50\n",
            "50000/50000 [==============================] - 11s 229us/step - loss: 0.6543 - acc: 0.7913 - val_loss: 0.7664 - val_acc: 0.7544\n",
            "Epoch 45/50\n",
            "50000/50000 [==============================] - 12s 230us/step - loss: 0.6494 - acc: 0.7901 - val_loss: 0.7487 - val_acc: 0.7773\n",
            "Epoch 46/50\n",
            "50000/50000 [==============================] - 12s 232us/step - loss: 0.6575 - acc: 0.7918 - val_loss: 0.7721 - val_acc: 0.7900\n",
            "Epoch 47/50\n",
            "50000/50000 [==============================] - 12s 233us/step - loss: 0.6542 - acc: 0.7913 - val_loss: 0.7776 - val_acc: 0.7423\n",
            "Epoch 48/50\n",
            "50000/50000 [==============================] - 11s 230us/step - loss: 0.6571 - acc: 0.7926 - val_loss: 0.8180 - val_acc: 0.7867\n",
            "Epoch 49/50\n",
            "50000/50000 [==============================] - 11s 229us/step - loss: 0.6582 - acc: 0.7878 - val_loss: 0.7021 - val_acc: 0.7737\n",
            "Epoch 50/50\n",
            "50000/50000 [==============================] - 11s 230us/step - loss: 0.6627 - acc: 0.7896 - val_loss: 0.7604 - val_acc: 0.7875\n",
            "Test loss: 0.7604275256156922\n",
            "Test accuracy: 0.7875\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0UJtVJQKz2s",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7dzOjahQk2e",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGBFvkj7IZou",
        "colab_type": "text"
      },
      "source": [
        "## 同樣運算 10 個 epochs，但 CNN 在 test data 的準確率顯著優於 DNN!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEmZVxuiIZow",
        "colab_type": "text"
      },
      "source": [
        "## 作業\n",
        "1. 請試著調整各個超參數，並說明那些超參數對於結果有明顯的影響?</br>\n",
        "</br>\n",
        "更改batch size = 32 ，訓練速度變慢，可是準確率意外地降低 0.7576=> 0.6334</br>\n",
        "更改更改filter大小 6*6 準確度下降 0.7576 => 0.6956 </br>\n",
        "增加epoch至50，精確度可已升高至 0.7578 => 0.7875 </br>\n",
        "</br>\n",
        "2. CNN 與 DNN 哪個模型的參數數量比較多? 造成參數的數量不同的原因在哪?\n",
        "DNN比CNN來的多，原因是DNN一開始就是做全連結，CNN經過卷積+池化，積過數次的降維"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WrGva126IZox",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}